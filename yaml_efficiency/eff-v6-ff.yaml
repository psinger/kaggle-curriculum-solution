architecture:
    backbone: microsoft/deberta-v3-xsmall
    dropout: 0.0
    embedding_size: 512
    intermediate_dropout: 0.0
    pool: '[CLS] token'
    pretrained: true
augmentation:
    token_mask_probability: 0.0
dataset:
    label_columns: label
    separator: ''
    test_dataframe: None
    text_column:
    - language
    - category
    - title
    - description
    train_dataframe: data/train_folded_v7.csv
environment:
    mixed_precision_training: true
    number_of_seeds_per_run: 1
    number_of_workers: 16
    seed: -1
experiment_name: eff-v6-ff
tokenizer:
    lowercase: false
    max_length: 48
    padding_quantile: 1.0
training:
    arcface_margin: 0.5
    arcface_scale: 15.0
    batch_size: 256
    differential_learning_rate: 0.0006
    differential_learning_rate_layers:
    - backbone
    drop_last_batch: true
    epochs: 30
    learning_rate: 0.003
    loss_function: ArcFaceLossAdaptiveMargin
    optimizer: AdamW
    schedule: Cosine
    warmup_epochs: 5
    weight_decay: 0.0
